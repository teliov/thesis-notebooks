{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisdomConfig:\n",
    "    url = None\n",
    "    port = None\n",
    "    username = None\n",
    "    password = None\n",
    "    env = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, layer_cofig):\n",
    "        super(DNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layer_config = layer_config\n",
    "        self.model = self.compose_model()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "    \n",
    "    def calculate_bound(self, weight):\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        return bound\n",
    "\n",
    "    def compose_model(self, layer_config=None):\n",
    "        if layer_config is None:\n",
    "            layer_config = self.layer_config\n",
    "        layers = OrderedDict()\n",
    "        for idx, config in enumerate(layer_config):\n",
    "            input_dim, output_dim = config\n",
    "            layer = nn.Linear(input_dim, output_dim)\n",
    "            nn.init.kaiming_uniform_(layer.weight,nonlinearity='relu')\n",
    "            bound = self.calculate_bound(layer.weight)\n",
    "            nn.init.uniform_(layer.bias, -bound, bound)\n",
    "            layers['linear-%d' % idx] = layer\n",
    "            if idx != len(layer_config) - 1:\n",
    "                layers['nonlinear-%d' % idx] = nn.ReLU()\n",
    "        \n",
    "        return nn.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AiBasicMedDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, transform=None):\n",
    "        self.data = self.data_to_tensor(data)\n",
    "        self.labels = self.labels_to_tensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def data_to_tensor(self, data):\n",
    "        return torch.FloatTensor(data.todense())\n",
    "\n",
    "    def labels_to_tensor(self, labels=None):\n",
    "        if labels is None:\n",
    "            return None\n",
    "\n",
    "        return torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data = self.data[idx, :]\n",
    "        if self.labels is not None:\n",
    "            labels = self.labels[idx]\n",
    "            return data, labels\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLSparseMaker(BaseEstimator):\n",
    "    \"\"\"\n",
    "    This makes the race feature a one hot encoded value instread\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_symptoms, age_mean=None, age_std=None):\n",
    "        self.num_symptoms = num_symptoms\n",
    "        self.age_std = age_std\n",
    "        self.age_mean = age_mean\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        self.age_mean = df['AGE'].mean()\n",
    "        self.age_std = df['AGE'].std()\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        if self.age_mean is None or self.age_std is None:\n",
    "            raise ValueError(\"mean and std for age have not been evaluated. Have you run fit ?\")\n",
    "        symptoms = df.SYMPTOMS\n",
    "        race = df.RACE\n",
    "\n",
    "        df = df.drop(columns=['SYMPTOMS', 'RACE'])\n",
    "        if 'LABEL' in df.columns:\n",
    "            df = df[['LABEL', 'AGE', 'GENDER']]\n",
    "        else:\n",
    "            df = df[['AGE', 'GENDER']]\n",
    "\n",
    "        df['AGE'] = (df['AGE'] - self.age_mean) / self.age_std\n",
    "\n",
    "        dense_matrix = sparse.coo_matrix(df.values)\n",
    "        symptoms = symptoms.apply(lambda v: [int(idx) + 5 for idx in v.split(\",\")])\n",
    "\n",
    "        columns = []\n",
    "        rows = []\n",
    "        for idx, val in enumerate(symptoms):\n",
    "            race_val = race.iloc[idx]\n",
    "            rows += [idx] * (len(val) + 1)  # takes care of the race: it's one hot encoded, so!\n",
    "            columns += [int(race_val)]\n",
    "            columns += val\n",
    "\n",
    "        data = np.ones(len(rows))\n",
    "        symptoms_race_coo = sparse.coo_matrix((data, (rows, columns)), shape=(df.shape[0], self.num_symptoms + 5))\n",
    "        return sparse.hstack([dense_matrix, symptoms_race_coo]).tocsc()\n",
    "\n",
    "    def fit_transform(self, df, y=None):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"/home/oagba/bulk/data/output_basic_15k/symptoms/csv/parsed/train.csv_sparse.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_symptoms = 376\n",
    "num_conditions = 801\n",
    "input_dim = 383\n",
    "train_batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(out, labels):\n",
    "    prob = F.log_softmax(out, dim=1)\n",
    "    _, preds = torch.max(out, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for batch, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "        with torch.no_grad():\n",
    "            acc = compute_accuracy(out, labels)\n",
    "        \n",
    "        accs.append(acc)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_loss = torch.stack(losses).mean().item()\n",
    "        batch_acc = torch.stack(accs).mean().item()\n",
    "    return batch_loss, batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, val_loader):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in val_loader:\n",
    "            out = model(batch)\n",
    "            loss = F.cross_entropy(out, labels)\n",
    "            losses.append(loss)\n",
    "            acc = compute_accuracy(out, labels)\n",
    "            accs.append(acc)\n",
    "        batch_loss = torch.stack(losses).mean().item()\n",
    "        batch_acc = torch.stack(accs).mean().item()\n",
    "    return batch_loss, batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, train_size):\n",
    "    split_selector = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        train_size=train_size\n",
    "    )\n",
    "\n",
    "    train_data = None\n",
    "    val_data = None\n",
    "    train_labels = None\n",
    "    val_labels = None\n",
    "    for train_index, val_index in split_selector.split(data, labels):\n",
    "        train_data = data.iloc[train_index]\n",
    "        val_data = data.iloc[val_index]\n",
    "        train_labels = labels[train_index]\n",
    "        val_labels = labels[val_index]\n",
    "\n",
    "    return train_data, train_labels, val_data, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_file, index_col=\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.LABEL.values\n",
    "df = df.drop(columns=['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels = split_data(df, labels, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsifier = DLSparseMaker(num_symptoms)\n",
    "sparsifier.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  38.741316816862515\n",
      "std:  23.380120690086834\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", sparsifier.age_mean)\n",
    "print(\"std: \", sparsifier.age_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sparsifier.transform(train_data)\n",
    "val_data = sparsifier.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AiBasicMedDataset(train_data, train_labels)\n",
    "val_data = AiBasicMedDataset(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=train_batch_size*2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_config = [\n",
    "    [383, 1024],\n",
    "    [1024, 1024],\n",
    "    [1024, 801]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(input_dim, num_conditions, layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "Tesla K40c with CUDA capability sm_35 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75.\n",
      "If you want to use the Tesla K40c GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "model = to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 2.2509398460388184.4f acc 0.46928438544273376.4f\n",
      "Epoch 2: loss: 1.4014298915863037.4f acc 0.5674718022346497.4f\n",
      "Epoch 3: loss: 1.3499873876571655.4f acc 0.5735849738121033.4f\n",
      "Epoch 4: loss: 1.3294744491577148.4f acc 0.5760802626609802.4f\n",
      "Epoch 5: loss: 1.3184858560562134.4f acc 0.5774691700935364.4f\n",
      "Epoch 6: loss: 1.3110846281051636.4f acc 0.578559935092926.4f\n",
      "Epoch 7: loss: 1.3059180974960327.4f acc 0.5791831612586975.4f\n",
      "Epoch 8: loss: 1.3019062280654907.4f acc 0.5801682472229004.4f\n",
      "Epoch 9: loss: 1.2986336946487427.4f acc 0.5808623433113098.4f\n",
      "Epoch 10: loss: 1.2959980964660645.4f acc 0.581196129322052.4f\n",
      "Epoch 11: loss: 1.2936228513717651.4f acc 0.5817708969116211.4f\n",
      "Epoch 12: loss: 1.2916280031204224.4f acc 0.5820255279541016.4f\n",
      "Epoch 13: loss: 1.2900021076202393.4f acc 0.5825397372245789.4f\n",
      "Epoch 14: loss: 1.2883979082107544.4f acc 0.5830676555633545.4f\n",
      "Epoch 15: loss: 1.2869853973388672.4f acc 0.5832527279853821.4f\n",
      "Epoch 16: loss: 1.2857179641723633.4f acc 0.5836137533187866.4f\n",
      "Epoch 17: loss: 1.284562110900879.4f acc 0.5838878750801086.4f\n",
      "Epoch 18: loss: 1.28348970413208.4f acc 0.5841419696807861.4f\n",
      "Epoch 19: loss: 1.2823700904846191.4f acc 0.5844336152076721.4f\n",
      "Epoch 20: loss: 1.2814254760742188.4f acc 0.5848221778869629.4f\n"
     ]
    }
   ],
   "source": [
    "# train for 20 epochs and see ...\n",
    "for idx in range(20):\n",
    "    loss, acc = train(model, train_loader, optimizer)\n",
    "    print(\"Epoch {}: loss: {}.4f acc {}.4f\".format(idx+1, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2909\t Val. Acc: 0.5800\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Loss: %.4f\\t Val. Acc: %.4f\" % (val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the learning rate\n",
    "new_learning_rate = learning_rate * 0.1\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = new_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another 10 epochs!?\n",
    "epoch_count = 20\n",
    "for idx in range(10):\n",
    "    loss, acc = train(model, train_loader, optimizer)\n",
    "    print(\"Epoch {}: loss: {}.4f acc {}.4f\".format(idx+1+epoch_count, loss, acc))\n",
    "\n",
    "epoch_count += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN(\n",
      "  (model): Sequential(\n",
      "    (linear-0): Linear(in_features=383, out_features=1024, bias=True)\n",
      "    (nonlinear-0): ReLU()\n",
      "    (linear-1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (nonlinear-1): ReLU()\n",
      "    (linear-2): Linear(in_features=1024, out_features=801, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2704\t Val. Acc: 0.5870\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Loss: %.4f\\t Val. Acc: %.4f\" % (val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the learning rate\n",
    "new_learning_rate /= 3\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = new_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another 10 epochs!?\n",
    "epoch_count = 30\n",
    "for idx in range(10):\n",
    "    loss, acc = train(model, train_loader, optimizer)\n",
    "    print(\"Epoch {}: loss: {}.4f acc {}.4f\".format(idx+1+epoch_count, loss, acc))\n",
    "\n",
    "epoch_count += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: loss: 1.253902792930603.4f acc 0.5941389799118042.4f\n",
      "Epoch 32: loss: 1.2536697387695312.4f acc 0.5939987301826477.4f\n",
      "Epoch 33: loss: 1.253538966178894.4f acc 0.5941035151481628.4f\n",
      "Epoch 34: loss: 1.2534538507461548.4f acc 0.594102144241333.4f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Epoch 31: loss: 1.253902792930603.4f acc 0.5941389799118042.4f\n",
    "Epoch 32: loss: 1.2536697387695312.4f acc 0.5939987301826477.4f\n",
    "Epoch 33: loss: 1.253538966178894.4f acc 0.5941035151481628.4f\n",
    "Epoch 34: loss: 1.2534538507461548.4f acc 0.594102144241333.4f\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2685\t Val. Acc: 0.5874\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Loss: %.4f\\t Val. Acc: %.4f\" % (val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_(out, labels):\n",
    "    prob = F.log_softmax(out, dim=1)\n",
    "    _, preds = torch.max(prob, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(model, val_loader):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in val_loader:\n",
    "            out = model(batch)\n",
    "            loss = F.cross_entropy(out, labels)\n",
    "            losses.append(loss)\n",
    "            acc = compute_accuracy_(out, labels)\n",
    "            accs.append(acc)\n",
    "        batch_loss = torch.stack(losses).mean().item()\n",
    "        batch_acc = torch.stack(accs).mean().item()\n",
    "    return batch_loss, batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = test_(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2685\t Val. Acc: 0.5874\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Loss: %.4f\\t Val. Acc: %.4f\" % (val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in val_loader:\n",
    "    d, l = item\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(out, labels):\n",
    "    _, preds = torch.max(out, dim=1)\n",
    "    if preds.is_cuda:\n",
    "        cpu_pred = preds.cpu().numpy()\n",
    "        cpu_labels = labels.cpu().numpy()\n",
    "    else:\n",
    "        cpu_pred = preds.numpy()\n",
    "        cpu_labels = labels.numpy()\n",
    "    return precision_score(cpu_labels, cpu_pred, average='weighted', zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-879ef00650c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dc3bda8e8a16>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prec = []\n",
    "    for item in val_loader:\n",
    "        d, l = item\n",
    "        out = model(d)\n",
    "        prec.append(compute_precision(out, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[383, 1024], [1024, 1024], [1024, 801]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 34: loss: 1.2534538507461548.4f acc 0.594102144241333.4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"output_dim\": num_conditions,\n",
    "    \"layer_config\": layer_config,\n",
    "    \"train_acc\": 0.594102144241333,\n",
    "    \"val_acc\": 0.5874,\n",
    "    \"train_loss\": 1.2534538507461548,\n",
    "    \"val_loss\": 1.2685,\n",
    "    \"epoch\": 30,\n",
    "    \"model_dict\": model.state_dict(),\n",
    "    \"age_std\": sparsifier.age_std,\n",
    "    \"age_mean\": sparsifier.age_mean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "opdir = \"/home/oagba/bulk/dl_runs/working/jupyter_basic_15k\"\n",
    "filename = os.path.join(opdir, \"run1.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-b00c1d519e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shares/bulk/oagba/work/medvice-parser/lib64/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;31m# Copy to a buffer, then serialize that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:31"
     ]
    }
   ],
   "source": [
    "torch.save(data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
