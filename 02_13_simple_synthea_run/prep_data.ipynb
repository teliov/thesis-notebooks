{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook preps the data exported from synthea using the \"sensible\" disease modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can use the *thesislib* package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from dateutil.parser import parse as date_parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils import pathutils\n",
    "from thesislib.utils import stringutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_csv = pathutils.get_data_file(\"simple-synthea/data/patients.csv\")\n",
    "patient_conditions_csv = pathutils.get_data_file(\"simple-synthea/data/patient_conditions.csv\")\n",
    "condition_symptom_csv = pathutils.get_data_file(\"simple-synthea/data/patient_condition_symptoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(patients_csv)\n",
    "conditions = pd.read_csv(patient_conditions_csv)\n",
    "symptoms = pd.read_csv(condition_symptom_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'PATIENT', 'CODE', 'DESCRIPTION', 'ONSET', 'DIAGNOSED'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_codes = conditions['CODE'].unique().tolist()\n",
    "condition_codes.sort()\n",
    "conditions_db = {code: conditions[conditions['CODE'] == code].iloc[0]['DESCRIPTION'] for code in condition_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_vector = symptoms['SYMPTOM_CODE'].unique().tolist()\n",
    "symptom_vector.sort()\n",
    "symptoms_db = {code: symptoms[symptoms['SYMPTOM_CODE'] == code].iloc[0]['SYMPTOM_DISPLAY'] for code in symptom_vector}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For \"similar\" diseases e.g the different types of sinusitis, (pharyngitis and Streptococcal sore throat) and the urinary tract infections, the symptoms are exactly (or almost exactly identical)\n",
    "\n",
    "Merging them would be an option. So we'd end up having 5 conditions as opposed to 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_count = {conditions_db[code]: conditions[conditions['CODE'] == code].shape[0] for code in condition_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Streptococcal sore throat (disorder)': 7669,\n",
       " 'Acute viral pharyngitis (disorder)': 26275,\n",
       " 'Viral sinusitis (disorder)': 45361,\n",
       " 'Sinusitis (disorder)': 2388,\n",
       " 'Acute bronchitis (disorder)': 8163,\n",
       " 'Acute bacterial sinusitis (disorder)': 2650,\n",
       " 'Asthma': 10,\n",
       " 'Escherichia coli urinary tract infection': 1142,\n",
       " 'Pyelonephritis': 21,\n",
       " 'Cystitis': 672,\n",
       " 'Childhood asthma': 226}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also encode the conditions one-hot-encoding\n",
    "condition_labels = {cnd: idx for idx, cnd in enumerate(condition_codes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_code = {'white': 0, 'black':1, 'asian':2, 'native':3, 'other':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['DESCRIPTION', 'DIAGNOSED', 'DEATHDATE', 'SSN', 'DRIVERS', 'PASSPORT', 'PREFIX', 'FIRST', 'LAST', \n",
    "              'SUFFIX', 'MAIDEN', 'MARITAL', 'ETHNICITY','BIRTHPLACE', 'ADDRESS', 'CITY', 'STATE',\n",
    "           'COUNTY', 'ZIP', 'LAT', 'LON', 'HEALTHCARE_EXPENSES', 'Id', 'Id_pat', 'SYMPTOM_DISPLAY', 'VALUE_CODE',\n",
    "           'VALUE_DISPLAY', 'HEALTHCARE_COVERAGE'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dump = pathutils.get_data_file(\"simple-synthea/output/data.json\")\n",
    "if os.path.exists(data_dump):\n",
    "    with open(data_dump) as fp:\n",
    "        design_matrix = json.load(fp)\n",
    "else:\n",
    "    # combine the dataframes\n",
    "    # conditions with patients\n",
    "    combined = conditions.merge(patients, how='left', left_on='PATIENT', right_on='Id', suffixes=('', '_pat'))\n",
    "    # symptoms with conditions\n",
    "    complete = symptoms.merge(combined, how='left', left_on='CONDITION_ID', right_on='Id', suffixes=('_symp', ''))\n",
    "    complete = complete.drop(columns=to_drop)\n",
    "    # are there conditions\n",
    "    # group by the condition id\n",
    "    condition_grp = complete.groupby(['CONDITION_ID'])\n",
    "    design_matrix = {\n",
    "        \"label\": [],\n",
    "        \"age\": [],\n",
    "        \"gender\": [],\n",
    "        \"race\": [],\n",
    "    }\n",
    "    design_matrix.update({item: [] for item in symptom_vector})\n",
    "    \n",
    "    for item, df in condition_grp.__iter__():\n",
    "        vector = {_: 0 for _ in symptom_vector}\n",
    "\n",
    "        onset_date = date_parser(df['ONSET'].iloc[0])\n",
    "        patient_birthdate = date_parser(df[\"BIRTHDATE\"].iloc[0])\n",
    "        vector['age'] =  abs(patient_birthdate.year - onset_date.year)\n",
    "        vector['gender'] = 0 if df['GENDER'].iloc[0] == 'F' else 1\n",
    "        vector['race'] = race_code[df['RACE'].iloc[0]]\n",
    "        vector['label'] = condition_labels[df['CODE'].iloc[0]]\n",
    "\n",
    "        # fill in the observations\n",
    "        for idx, symptom_code in df[\"SYMPTOM_CODE\"].items():\n",
    "            vector[symptom_code] = 1\n",
    "\n",
    "        for k,v in vector.items():\n",
    "            design_matrix[k].append(v)\n",
    "        \n",
    "    with open(data_dump, 'w') as fp:\n",
    "        json.dump(design_matrix, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dump = pathutils.get_data_file(\"simple-synthea/output/test.json\")\n",
    "train_dump = pathutils.get_data_file(\"simple-synthea/output/train.json\")\n",
    "\n",
    "if os.path.exists(test_dump) and os.path.exists(train_dump):\n",
    "    train_data = pd.read_json(train_dump)\n",
    "    test_data = pd.read_json(test_dump)\n",
    "    \n",
    "    train_labels = train_data['labels']\n",
    "    train_df = train_data.drop(columns=[\"labels\"])\n",
    "    test_labels = test_data['labels']\n",
    "    test_df = test_data.drop(columns=[\"labels\"])\n",
    "else:\n",
    "    data_df = pd.DataFrame(design_matrix)\n",
    "    \n",
    "    # let's keep a test set which we would use for evaluation, \n",
    "    split_t = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "    data_X = data_df.drop(columns=['label'])\n",
    "    data_Y = data_df['label']\n",
    "    \n",
    "    train_df = None\n",
    "    train_labels = None\n",
    "    test_df = None\n",
    "    test_labels = None\n",
    "    \n",
    "    for train_index, test_index in split_t.split(data_X, data_Y):\n",
    "        train_df = data_X.iloc[train_index]\n",
    "        test_df = data_X.iloc[test_index]\n",
    "        train_labels = data_Y.iloc[train_index]\n",
    "        test_labels = data_Y.iloc[test_index]\n",
    "    \n",
    "    train_data = train_df.copy()\n",
    "    train_data['labels'] = train_labels\n",
    "    \n",
    "    test_data = test_df.copy()\n",
    "    test_data['labels'] = test_labels\n",
    "    \n",
    "    train_data.to_json(train_dump)\n",
    "    test_data.to_json(test_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some ML\n",
    "clf = RandomForestClassifier(n_estimators=140, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=2, random_state=None, verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.fit(train_df, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on the train set\n",
    "train_predictions = res.predict(train_df)\n",
    "diff = (train_predictions - train_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(train_predictions)\n",
    "accuracy = (num_labels - num_missed)*1.0/num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Missed 5096 predictions out of 85119 samples for an accuracy of 0.940\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = res.predict(test_df)\n",
    "diff = (test_predictions - test_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(test_predictions)\n",
    "accuracy = (num_labels - num_missed) * 1.0/num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Missed 585 predictions out of 9458 samples for an accuracy of 0.938\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_mat = confusion_matrix(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6,  3,  0,  5,  1,  9,  8,  2,  4,  7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tConfusion Matrix for Test Set\n",
      "\t\t\t\t=============================\n",
      "\n",
      "              AcBr(d    Si(d    Cy    StSoTh(d    Py    AcBaSi(d    AcViPh(d    As    ChAs    EsCoUrTrIn    ViSi(d\n",
      "----------  --------  ------  ----  ----------  ----  ----------  ----------  ----  ------  ------------  --------\n",
      "AcBr(d           816       0     0           0     0           0           0     0       0             0         0\n",
      "Si(d               0       0     0           0     0           0           0     0       0             0       239\n",
      "Cy                 0       0     7           0     0           0           0     0       0            60         0\n",
      "StSoTh(d           0       0     0         767     0           0           0     0       0             0         0\n",
      "Py                 0       0     0           0     0           0           0     0       0             2         0\n",
      "AcBaSi(d           0       0     0           0     0           0           0     0       0             0       265\n",
      "AcViPh(d           0       0     0           0     0           0        2628     0       0             0         0\n",
      "As                 0       0     0           0     0           0           0     1       0             0         0\n",
      "ChAs               0       0     0           0     0           0           0     0      23             0         0\n",
      "EsCoUrTrIn         0       0    15           0     0           0           0     0       0            99         0\n",
      "ViSi(d             0       2     0           0     0           2           0     0       0             0      4532\n"
     ]
    }
   ],
   "source": [
    "condition_names = []\n",
    "for val in condition_codes:\n",
    "    parts = conditions_db[val].split(\" \")\n",
    "    if len(parts) == 1:\n",
    "        itm = parts[0]\n",
    "        condition_names.append(itm[0].upper() + itm[1].lower())\n",
    "    else:\n",
    "        itm = \"\"\n",
    "        for st in parts:\n",
    "            itm += st[0].upper() + st[1].lower()\n",
    "        condition_names.append(itm)\n",
    "\n",
    "\n",
    "table = []\n",
    "for idx in range(len(condition_names)):\n",
    "    data = [condition_names[idx]] + cnf_mat[idx, :].tolist()\n",
    "    table.append(data)\n",
    "\n",
    "\n",
    "print(\"\\t\\t\\t\\tConfusion Matrix for Test Set\\n\\t\\t\\t\\t=============================\\n\")\n",
    "print(tabulate(table, headers=condition_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are in line with thinking. The confusion only arises from from conditions that have the same symptoms:\n",
    "- There is a confusion amongs the sinusitis, with more often than not Viral Sinusitis (the more prevalent condition getting the majority vote)\n",
    "- Also a confusion amongst the Urinary tract infections. More often than not urethritis gets the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic solution\n",
    "# we do not need any ML for this. A simple for loop will do the trick\n",
    "# We know that every condition presents the same symptoms, so we handle this. \n",
    "# use a binary encoded symptom vector to denote the symptom and then we use that value in an if statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_symptoms = len(symptom_vector)\n",
    "condition_symptom_binary = {code: [0 for idx in range(num_symptoms)] for code in condition_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill them in\n",
    "for code in condition_symptom_binary:\n",
    "    condition_id = conditions[conditions['CODE'] == code].iloc[0]['Id']\n",
    "    cond_symptoms = symptoms[symptoms['CONDITION_ID'] == condition_id]['SYMPTOM_CODE'].tolist()\n",
    "    for idx, itm in enumerate(symptom_vector):\n",
    "        if itm in cond_symptoms:\n",
    "            condition_symptom_binary[code][idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_symptom_int = {code: stringutils.binary_seq_to_decimal(val) for code, val in condition_symptom_binary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the symptom score we can then determine which is the disease\n",
    "def deterministic_rule_system(vector):\n",
    "    int_val = stringutils.binary_seq_to_decimal(vector)\n",
    "    if int_val == 33818736:\n",
    "        # either 195967001 or 233678006 (Asthma or Childhood asthma)\n",
    "        # pick childhood asthma because it's more prevalent\n",
    "        return 233678006\n",
    "    elif int_val == 36563072:\n",
    "        return 10509002 # Acute bronchitis\n",
    "    elif int_val == 68162433:\n",
    "        # either Cystitis, Pyelonephritis, or Urethritis. Pick Urethritis because it's more prevalent\n",
    "        return 301011002\n",
    "    elif int_val == 193347716:\n",
    "        # either Sinusitis or Viral Sinusitis or Bacterial Sinusitis. Pick Viral Sinusitis because it's more prevalent\n",
    "        return 444814009\n",
    "    elif int_val == 272688266:\n",
    "        return 43878008 # strep throat\n",
    "    elif int_val == 272950410:\n",
    "        return 195662009 # acute viral pharyngitis\n",
    "    else:\n",
    "        raise ValueError(\"Unknown symptom combination\")\n",
    "\n",
    "def toy_predict(test_samples):\n",
    "    symptom_vector_idx = {itm: idx for idx, itm in enumerate(symptom_vector)}\n",
    "    predictions = []\n",
    "    for index, row in test_samples.iterrows():\n",
    "        bin_vector = [0 for idx in range(len(symptom_vector))]\n",
    "        for jdex, val in row.items():\n",
    "            if jdex not in symptom_vector_idx:\n",
    "                continue\n",
    "            bin_vector[symptom_vector_idx[jdex]] = int(val)\n",
    "        prediction = deterministic_rule_system(bin_vector)\n",
    "        predictions.append(condition_labels[prediction])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_test_predictions = toy_predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (det_test_predictions - test_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(test_predictions)\n",
    "accuracy = (num_labels - num_missed) * 1.0/num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Missed 574 predictions out of 9458 samples for an accuracy of 0.939\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_cnf_mat = confusion_matrix(test_labels, det_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t Det. Confusion Matrix for Test Set\n",
      "\t\t\t\t=====================================\n",
      "\n",
      "              AcBr(d    Si(d    Cy    StSoTh(d    Py    AcBaSi(d    AcViPh(d    As    ChAs    EsCoUrTrIn    ViSi(d\n",
      "----------  --------  ------  ----  ----------  ----  ----------  ----------  ----  ------  ------------  --------\n",
      "AcBr(d           816       0     0           0     0           0           0     0       0             0         0\n",
      "Si(d               0       0     0           0     0           0           0     0       0             0       239\n",
      "Cy                 0       0     0           0     0           0           0     0       0            67         0\n",
      "StSoTh(d           0       0     0         767     0           0           0     0       0             0         0\n",
      "Py                 0       0     0           0     0           0           0     0       0             2         0\n",
      "AcBaSi(d           0       0     0           0     0           0           0     0       0             0       265\n",
      "AcViPh(d           0       0     0           0     0           0        2628     0       0             0         0\n",
      "As                 0       0     0           0     0           0           0     0       1             0         0\n",
      "ChAs               0       0     0           0     0           0           0     0      23             0         0\n",
      "EsCoUrTrIn         0       0     0           0     0           0           0     0       0           114         0\n",
      "ViSi(d             0       0     0           0     0           0           0     0       0             0      4536\n"
     ]
    }
   ],
   "source": [
    "condition_names = []\n",
    "for val in condition_codes:\n",
    "    parts = conditions_db[val].split(\" \")\n",
    "    if len(parts) == 1:\n",
    "        itm = parts[0]\n",
    "        condition_names.append(itm[0].upper() + itm[1].lower())\n",
    "    else:\n",
    "        itm = \"\"\n",
    "        for st in parts:\n",
    "            itm += st[0].upper() + st[1].lower()\n",
    "        condition_names.append(itm)\n",
    "\n",
    "\n",
    "table = []\n",
    "for idx in range(len(condition_names)):\n",
    "    data = [condition_names[idx]] + det_cnf_mat[idx, :].tolist()\n",
    "    table.append(data)\n",
    "\n",
    "\n",
    "print(\"\\t\\t\\t\\t Det. Confusion Matrix for Test Set\\n\\t\\t\\t\\t=====================================\\n\")\n",
    "print(tabulate(table, headers=condition_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we are able to achieve the same results as the random forest following this simple rule!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
