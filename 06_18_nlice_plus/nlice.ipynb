{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /Users/teliov/TUD/Thesis/Medvice/Notebooks/data/04_06_new_data/data/split\n",
    "# So we can use the *thesislib* package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils import pathutils\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils.ml import process\n",
    "from thesislib.utils.ml import runners, models\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "_ = importlib.reload(naive_bayes)\n",
    "_ = importlib.reload(process)\n",
    "_ = importlib.reload(models)\n",
    "_ = importlib.reload(runners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathutils.get_data_file(\"06_18_nlice_plus\")\n",
    "nlice_data_dir = os.path.join(data_dir, \"nlice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlice_module_dir = \"/Users/teliov/TUD/symcat-to-synthea/output/module_ai_med_plus_nlice\"\n",
    "nlice_data_csv = pathutils.get_data_file(\"06_18_nlice_plus/ai/output_med_ai_plus_nlice/symptoms/csv/symptoms.csv\")\n",
    "nlice_op_data_dir = os.path.join(nlice_data_dir, \"data\")\n",
    "nlice_parsed_data_dir = os.path.join(nlice_op_data_dir, \"parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_map_file = os.path.join(nlice_op_data_dir, \"transformation_map.json\")\n",
    "encoding_map_file = os.path.join(nlice_op_data_dir, \"encoding_map.json\")\n",
    "reduction_map_file = os.path.join(nlice_op_data_dir, \"reduction_map.json\")\n",
    "encoding_count_file = os.path.join(nlice_op_data_dir, \"encoding_count.json\")\n",
    "nlice_symptoms_file = os.path.join(nlice_op_data_dir, \"nlice_symptoms.json\")\n",
    "with open(transformation_map_file) as fp:\n",
    "    transformation_map = json.load(fp)\n",
    "with open(encoding_map_file) as fp:\n",
    "    encoding_map = json.load(fp)\n",
    "with open(reduction_map_file) as fp:\n",
    "    reduction_map = json.load(fp)\n",
    "with open(nlice_symptoms_file) as fp:\n",
    "    nlice_symptoms = json.load(fp)\n",
    "\n",
    "reverse_encoding_map = {}\n",
    "for key, value in encoding_map.items():\n",
    "    rev_value = {v:k for k, v in value.items()}\n",
    "    reverse_encoding_map[key] = rev_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into a train and test set\n",
    "nlice_train_file, nlice_test_file = process.split_data(nlice_data_csv, nlice_op_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_symptom_map_file = pathutils.get_data_file(\"06_18_nlice_plus/basic/symptom_db.json\")\n",
    "basic_condition_map_file = pathutils.get_data_file(\"06_18_nlice_plus/basic/condition_db.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the train set and let's train\n",
    "nlice_parsed_train = process.parse_data(\n",
    "    nlice_train_file,\n",
    "    basic_condition_map_file,\n",
    "    basic_symptom_map_file,\n",
    "    nlice_parsed_data_dir,\n",
    "    is_nlice=True,\n",
    "    transform_map=transformation_map,\n",
    "    encode_map=encoding_map,\n",
    "    reduce_map=reduction_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with RF and then with NB\n",
    "nlice_rf_dir = os.path.join(nlice_op_data_dir, \"output/rf\")\n",
    "rfparams = models.RFParams()\n",
    "rfparams.n_estimators = 20\n",
    "rfparams.max_depth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ok = runners.train_ai_med_rf(\n",
    "    nlice_parsed_train,\n",
    "    basic_symptom_map_file,\n",
    "    nlice_rf_dir,\n",
    "    rfparams,\n",
    "    \"NLICE AI-MED Run\",\n",
    "    \"local-pc\",\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NB\n",
    "nlice_nb_dir = os.path.join(nlice_op_data_dir, \"output/nb\")\n",
    "nlice_symptom_hash = []\n",
    "nlice_symptom_encoding = {}\n",
    "for item in nlice_symptoms:\n",
    "    _hash = hashlib.sha224(item.encode('utf-8')).hexdigest() \n",
    "    nlice_symptom_hash.append(_hash)\n",
    "    nlice_symptom_encoding[_hash] = reverse_encoding_map[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ok = runners.train_ai_med_nb(\n",
    "    nlice_parsed_train,\n",
    "    basic_symptom_map_file,\n",
    "    nlice_nb_dir,\n",
    "    \"NLICE AI-MED Run\",\n",
    "    \"local-pc\",\n",
    "    True,\n",
    "    nlice_symptom_hash,\n",
    "    nlice_symptom_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1,2,3,4,4,5,5, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit(arr.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5, 8])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.transform(arr.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
