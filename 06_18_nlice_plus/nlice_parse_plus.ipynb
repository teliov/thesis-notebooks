{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /Users/teliov/TUD/Thesis/Medvice/Notebooks/data/04_06_new_data/data/split\n",
    "# So we can use the *thesislib* package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils import pathutils\n",
    "import json\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_dir = pathutils.get_data_file(\"06_18_nlice_plus/nlice/data\")\n",
    "pathlib.Path(op_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_med_data_file = pathutils.get_data_file('definitions/ai-med-plus.json')\n",
    "with open(ai_med_data_file) as fp:\n",
    "    ai_med_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to determine the groupings for every symptom that exists\n",
    "symptom_combinations = {}\n",
    "nlice_key_set = []\n",
    "for value in ai_med_data.values():\n",
    "    symptoms = value.get(\"symptoms\")\n",
    "    for symptom in symptoms.values():\n",
    "        slug = symptom.get(\"slug\")\n",
    "        nlice = symptom.get(\"nlice\", {})\n",
    "        if slug not in symptom_combinations:\n",
    "            symptom_combinations[slug] = {\n",
    "                \"nature\": [\"0-None\"],\n",
    "                \"vas\": [\"0-None\"],\n",
    "                \"duration\": [\"0-None\"],\n",
    "                \"location\": [\"0-None\"]\n",
    "            }\n",
    "        combo = symptom_combinations[slug]\n",
    "        for nlice_key, nlice_values in nlice.items():\n",
    "            nlice_list = list(nlice_values.keys())\n",
    "            nlice_key_set.append(nlice_key)\n",
    "            curr_list = combo.get(nlice_key, [])\n",
    "            new_list = sorted(list(set(curr_list + nlice_list)))\n",
    "            \n",
    "            combo[nlice_key] = new_list\n",
    "        symptom_combinations[slug] = combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some replacements\n",
    "symptom_combinations[\"headache\"][\"nature\"] = [\"0-None\", \"aching\", \"stabbing\"]\n",
    "symptom_combinations[\"abdominal_pain\"][\"location\"] = [\"0-None\", \"llq\", \"luq\", \"rlq\", \"ruq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_map = {\n",
    "    \"headache\": {\n",
    "        \"thunderclap\": \"stabbing\",\n",
    "        \"throbbing\": \"aching\",\n",
    "        \"pressure\": \"aching\"\n",
    "    },\n",
    "    \"abdominal_pain\": {\n",
    "        \"epigastric\": \"ruq\",\n",
    "        \"left-abdomen\": \"llq\",\n",
    "        \"right-abdomen\": \"rlq\",\n",
    "        \"umbilical\": \"rlq\",\n",
    "        \"upper-abdomen\": \"luq\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each symptom, create a map of the possible combinations\n",
    "# assumption is that only one nature is possible\n",
    "import itertools\n",
    "\n",
    "symptom_combination_encoding_map = {}\n",
    "for key, value in symptom_combinations.items():\n",
    "    nature = value.get(\"nature\")\n",
    "    vas = value.get(\"vas\")\n",
    "    duration = value.get(\"duration\")\n",
    "    location = value.get(\"location\")\n",
    "    \n",
    "    combos = itertools.product(nature, vas, duration, location)\n",
    "    combos = map(lambda item: \";\".join(item).strip(), combos)\n",
    "    combos = list(filter(lambda item: len(item) > 0, combos))    \n",
    "\n",
    "    encoding = {}\n",
    "    for idx, combo in enumerate(combos):\n",
    "        encoding[combo] = idx+1\n",
    "    symptom_combination_encoding_map[key] = encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlice_symptoms = [key for key in symptom_combination_encoding_map if len(symptom_combination_encoding_map[key]) > 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import hashlib\n",
    "def slugify_condition(condition_name):\n",
    "    condition_name = condition_name.lower()\n",
    "    condition_name = re.sub(r\"\\s+\", \"-\", condition_name)\n",
    "    condition_name = re.sub(r\"'\", \"-\", condition_name)\n",
    "    condition_name = re.sub(r\"\\(\", \"\", condition_name)\n",
    "    condition_name = re.sub(r\"\\)\", \"\", condition_name)\n",
    "    return condition_name\n",
    "\n",
    "def get_symptom_condition_map(module_dir):\n",
    "    module_files = glob(os.path.join(module_dir, \"*.json\"))\n",
    "    symptom_map = {}\n",
    "    condition_map = {}\n",
    "    for file in module_files:\n",
    "        with open(file) as fp:\n",
    "            module = json.load(fp)\n",
    "        states = module.get(\"states\")\n",
    "        for state in states.values():\n",
    "            if state.get(\"type\") != \"Symptom\" and state.get(\"type\") != \"ConditionOnset\":\n",
    "                continue\n",
    "            if state.get(\"type\") == \"ConditionOnset\":\n",
    "                code = state.get(\"codes\")[0]\n",
    "                condition_map[code[\"code\"]] = slugify_condition(code.get(\"display\"))\n",
    "                continue\n",
    "            symptom_code = state.get(\"symptom_code\")\n",
    "            slug = slugify_condition(symptom_code.get(\"display\"))\n",
    "            slug_hash  = hashlib.sha224(slug.encode(\"utf-8\")).hexdigest()\n",
    "            symptom_map[slug_hash] = slug\n",
    "    return symptom_map, condition_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlice_module_dir = \"/Users/teliov/TUD/symcat-to-synthea/output/module_ai_med_plus_nlice\"\n",
    "nlice_symptom_map, nlice_condition_map = get_symptom_condition_map(nlice_module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_symptom_map = {key: value for key, value in nlice_symptom_map.items() if \"nlice\" not in value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {value: key for key, value in actual_symptom_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlice_regex = re.compile(\"(.*)\\-nlice-(.*)-(.*)\")\n",
    "nlice_transformation_map = {}\n",
    "for key, value in nlice_symptom_map.items():\n",
    "    match = nlice_regex.match(value)\n",
    "    if match is None:\n",
    "        xform = {\n",
    "            \"symptom\": value,\n",
    "            \"nlice\":  None,\n",
    "            \"value\": None\n",
    "        }\n",
    "    else:\n",
    "        xform = {\n",
    "            \"symptom\": match.group(1),\n",
    "            \"nlice\": match.group(2),\n",
    "            \"value\": match.group(3)\n",
    "        }\n",
    "    nlice_transformation_map[key] = xform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_symptoms(symptom_str, transformation_map, symptom_combination_encoding_map, reduction_map):\n",
    "    symptom_list = symptom_str.split(\";\")\n",
    "    symptoms = {}\n",
    "    for item in symptom_list:\n",
    "        transformed = transformation_map.get(item)\n",
    "        name = transformed.get(\"symptom\")\n",
    "        if name not in symptoms:\n",
    "            symptoms[name] = {\n",
    "                \"nature\": \"0-None\",\n",
    "                \"vas\": \"0-None\",\n",
    "                \"duration\": \"0-None\",\n",
    "                \"location\": \"0-None\"\n",
    "            }\n",
    "        nlice = transformed.get(\"nlice\")\n",
    "        nlice_value = transformed.get(\"value\")\n",
    "        if nlice is not None and nlice_value is not None:\n",
    "            if name in reduction_map and nlice_value in reduction_map[name]:\n",
    "                nlice_value = reduction_map[name][nlice_value]\n",
    "            symptoms[name][nlice] = nlice_value\n",
    "        \n",
    "    transformed_symptoms = []\n",
    "    for key, value in symptoms.items():\n",
    "        ordered = [value.get(item) for item in [\"nature\", \"vas\", \"duration\", \"location\"]]\n",
    "        ordered = \";\".join(ordered)\n",
    "        encoding = symptom_combination_encoding_map[key][ordered]\n",
    "        symptom_hash = hashlib.sha224(key.encode(\"utf-8\")).hexdigest()\n",
    "        transformed_symptoms.append(\"|\".join([symptom_hash, str(encoding)]))\n",
    "    return \";\".join(transformed_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(key):\n",
    "    return hashlib.sha224(key.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_map_file = os.path.join(op_dir, \"transformation_map.json\")\n",
    "encoding_map_file = os.path.join(op_dir, \"encoding_map.json\")\n",
    "encoding_count_file = os.path.join(op_dir, \"encoding_count.json\")\n",
    "reduction_map_file = os.path.join(op_dir, \"reduction_map.json\")\n",
    "nlice_symptoms_file = os.path.join(op_dir, \"nlice_symptoms.json\")\n",
    "with open(transformation_map_file, \"w\") as fp:\n",
    "    json.dump(nlice_transformation_map, fp, indent=4)\n",
    "with open(encoding_map_file, \"w\") as fp:\n",
    "    json.dump(symptom_combination_encoding_map, fp, indent=4)\n",
    "with open(reduction_map_file, \"w\") as fp:\n",
    "    json.dump(reduction_map, fp, indent=4)\n",
    "with open(encoding_count_file, \"w\") as fp:\n",
    "    encounding_count = {get_hash(key): len(symptom_combination_encoding_map[key]) for key in symptom_combination_encoding_map}\n",
    "    json.dump(encounding_count, fp)\n",
    "with open(nlice_symptoms_file, \"w\") as fp:\n",
    "    json.dump(nlice_symptoms, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "abdominal_pain_cats = symptom_combination_encoding_map['abdominal_pain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(cat1, cat2):\n",
    "    cat_1 = cat1.split(\";\")\n",
    "    cat_2 = cat2.split(\";\")\n",
    "    \n",
    "    dist = 0\n",
    "    for idx in range(len(cat_1)):\n",
    "        if cat_1[idx] != cat_2[idx]:\n",
    "            dist += 1\n",
    "    return dist\n",
    "\n",
    "cat1 = '0-None;0-None;0-None;0-None'\n",
    "cat2 = '0-None;0-None;0-None;ruq'\n",
    "cat3 = 'cramping;mild;medium;llq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat1-Cat2: 1\n",
      "Cat1-Cat2: 4\n",
      "Cat1-Cat2: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Cat1-Cat2: %d\" % calc_distance(cat1, cat2))\n",
    "print(\"Cat1-Cat2: %d\" % calc_distance(cat1, cat3))\n",
    "print(\"Cat1-Cat2: %d\" % calc_distance(cat2, cat3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
