{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can use the *thesislib* package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from dateutil.parser import parse as date_parser\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils import pathutils\n",
    "from thesislib.utils.ml import report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_csv = pathutils.get_data_file(\"prob-synthea-1/data/patients.csv\")\n",
    "patient_conditions_csv = pathutils.get_data_file(\"prob-synthea-1/data/patient_conditions.csv\")\n",
    "condition_symptom_csv = pathutils.get_data_file(\"prob-synthea-1/data/patient_condition_symptoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(patients_csv)\n",
    "conditions = pd.read_csv(patient_conditions_csv)\n",
    "symptoms = pd.read_csv(condition_symptom_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_codes = conditions['CODE'].unique().tolist()\n",
    "condition_codes.sort()\n",
    "conditions_db = {code: conditions[conditions['CODE'] == code].iloc[0]['DESCRIPTION'] for code in condition_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_vector = symptoms['SYMPTOM_CODE'].unique().tolist()\n",
    "symptom_vector.sort()\n",
    "symptoms_db = {code: symptoms[symptoms['SYMPTOM_CODE'] == code].iloc[0]['SYMPTOM_DISPLAY'] for code in symptom_vector}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If we wanted to grab the full set of symptoms and not just those appearing in the available data:\n",
    "\n",
    "```python\n",
    "with open(\"synthea/symptoms_db.json\") as fp:\n",
    "    symptom_db = json.load(fp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Urethritis': 37740, 'Asthma': 39700, 'Acute sinusitis': 39458, 'Pharyngitis': 39771, 'Pyelonephritis': 38265, 'Acute bronchitis': 39669, 'Strep throat': 39664, 'Chronic sinusitis': 39675, 'Cystitis': 38200}\n"
     ]
    }
   ],
   "source": [
    "condition_count = {conditions_db[code]: conditions[conditions['CODE'] == code].shape[0] for code in condition_codes}\n",
    "print(condition_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also encode the conditions one-hot-encoding\n",
    "condition_labels = {code: idx for idx, code in enumerate(condition_codes)}\n",
    "_condition_index_map = {condition_labels[code]: conditions_db[code] for code in condition_labels.keys()}\n",
    "with open(pathutils.get_data_file(\"prob-synthea-1/output/labels_map.json\"), \"w\") as fp:\n",
    "    json.dump(_condition_index_map, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_code = {'white': 0, 'black':1, 'asian':2, 'native':3, 'other':4}\n",
    "inverse_race_code = ['white', 'black', 'asian', 'native', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dataframes\n",
    "# conditions with patients\n",
    "combined = conditions.merge(patients, how='left', left_on='PATIENT', right_on='Id', suffixes=('', '_pat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symptoms with conditions\n",
    "complete = symptoms.merge(combined, how='left', left_on='CONDITION_ID', right_on='Id', suffixes=('_symp', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['DESCRIPTION', 'DIAGNOSED', 'DEATHDATE', 'SSN', 'DRIVERS', 'PASSPORT', 'PREFIX', 'FIRST', 'LAST', \n",
    "              'SUFFIX', 'MAIDEN', 'MARITAL', 'ETHNICITY','BIRTHPLACE', 'ADDRESS', 'CITY', 'STATE',\n",
    "           'COUNTY', 'ZIP', 'LAT', 'LON', 'HEALTHCARE_EXPENSES', 'Id', 'Id_pat', 'SYMPTOM_DISPLAY', 'VALUE_CODE',\n",
    "           'VALUE_DISPLAY', 'HEALTHCARE_COVERAGE'\n",
    "          ]\n",
    "complete = complete.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there conditions\n",
    "# group by the condition id\n",
    "condition_grp = complete.groupby(['CONDITION_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathutils.get_data_file(\"prob-synthea-1/output\")\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dump = os.path.join(output_dir, \"data.json\")\n",
    "if os.path.exists(data_dump) and False:\n",
    "    with open(data_dump) as fp:\n",
    "        design_matrix = json.load(fp)\n",
    "else:\n",
    "    design_matrix = {\n",
    "        \"label\": [],\n",
    "        \"age\": [],\n",
    "        \"gender\": [],\n",
    "        \"race\": [],\n",
    "    }\n",
    "\n",
    "    for item in symptom_vector:\n",
    "        design_matrix[item] = []\n",
    "    # build the design matrix\n",
    "    for item, df in condition_grp:\n",
    "        vector = {_: 0 for _ in symptom_vector}\n",
    "\n",
    "        onset_date = date_parser(df['ONSET'].iloc[0])\n",
    "        patient_birthdate = date_parser(df[\"BIRTHDATE\"].iloc[0])\n",
    "        vector['age'] =  abs(patient_birthdate.year - onset_date.year)\n",
    "        vector['gender'] = 0 if df['GENDER'].iloc[0] == 'F' else 1\n",
    "        vector['race'] = race_code[df['RACE'].iloc[0]]\n",
    "        vector['label'] = condition_labels[df['CODE'].iloc[0]]\n",
    "\n",
    "        # fill in the observations\n",
    "        for idx, symptom_code in df[\"SYMPTOM_CODE\"].items():\n",
    "            vector[symptom_code] = 1\n",
    "\n",
    "        for k,v in vector.items():\n",
    "            design_matrix[k].append(v)\n",
    "    with open(data_dump, 'w') as fp:\n",
    "        json.dump(design_matrix, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dump = os.path.join(output_dir, \"train.json\")\n",
    "test_dump = os.path.join(output_dir, \"test.json\")\n",
    "\n",
    "if os.path.exists(test_dump) and os.path.exists(train_dump):\n",
    "    train_data = pd.read_json(train_dump)\n",
    "    test_data = pd.read_json(test_dump)\n",
    "    \n",
    "    train_labels = train_data['labels']\n",
    "    train_df = train_data.drop(columns=[\"labels\"])\n",
    "    test_labels = test_data['labels']\n",
    "    test_df = test_data.drop(columns=[\"labels\"])\n",
    "else:\n",
    "    data_df = pd.DataFrame(design_matrix)\n",
    "    \n",
    "    # let's keep a test set which we would use for evaluation, \n",
    "    split_t = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "    data_X = data_df.drop(columns=['label'])\n",
    "    data_Y = data_df['label']\n",
    "    \n",
    "    train_df = None\n",
    "    train_labels = None\n",
    "    test_df = None\n",
    "    test_labels = None\n",
    "    \n",
    "    for train_index, test_index in split_t.split(data_X, data_Y):\n",
    "        train_df = data_X.iloc[train_index]\n",
    "        test_df = data_X.iloc[test_index]\n",
    "        train_labels = data_Y.iloc[train_index]\n",
    "        test_labels = data_Y.iloc[test_index]\n",
    "    \n",
    "    train_data = train_df.copy()\n",
    "    train_data['labels'] = train_labels\n",
    "    \n",
    "    test_data = test_df.copy()\n",
    "    test_data['labels'] = test_labels\n",
    "    \n",
    "    train_data.to_json(train_dump)\n",
    "    test_data.to_json(test_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_s = train_data.iloc[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 8\n",
      "gender male\n",
      "race white\n",
      "Painful sinuses 0\n",
      "Frontal headache 0\n",
      "Itching of skin 0\n",
      "Coryza 1\n",
      "Nasal congestion 1\n",
      "Sharp chest pain 0\n",
      "Blood in urine 0\n",
      "Low back pain 0\n",
      "Penis pain 0\n",
      "Shortness of breath 0\n",
      "Ache all over 0\n",
      "Cough 1\n",
      "Retention of urine 0\n",
      "Headache 0\n",
      "Decreased appetite 0\n",
      "Lower abdominal pain 0\n",
      "Suprapubic pain 0\n",
      "Side pain 0\n",
      "Facial pain 0\n",
      "Penile discharge 0\n",
      "Vomiting 0\n",
      "Painful urination 0\n",
      "Symptoms of bladder 0\n",
      "Skin rash 0\n",
      "Hurts to breath 0\n",
      "Vaginal itching 0\n",
      "Ear pain 1\n",
      "Frequent urination 0\n",
      "Nausea 0\n",
      "Difficulty in swallowing 0\n",
      "Sore throat 0\n",
      "Sharp abdominal pain 0\n",
      "Allergic reaction 0\n",
      "Sinus congestion 1\n",
      "Coughing up sputum 0\n",
      "Chills 0\n",
      "Congestion in chest 0\n",
      "Fever 0\n",
      "Hoarse voice 0\n",
      "Involuntary urination 0\n",
      "Wheezing 0\n",
      "Chest tightness 0\n",
      "Back pain 0\n",
      "Pelvic pain 0\n",
      "Difficulty breathing 0\n",
      "Pain in testicles 0\n",
      "labels 7\n"
     ]
    }
   ],
   "source": [
    "for label, item in _s.iteritems():\n",
    "    if len(label) == 56:\n",
    "        print(symptoms_db[label], item)\n",
    "    elif label == 'race':\n",
    "        print(label, inverse_race_code[item])\n",
    "    elif label == 'gender':\n",
    "        print(label, \"female\" if item == 0 else \"male\")\n",
    "    else:\n",
    "        print(label, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=140, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=2, random_state=None, verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.fit(train_df, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on the train set\n",
    "train_predictions = res.predict(train_df)\n",
    "diff = (train_predictions - train_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(train_predictions)\n",
    "accuracy = (num_labels - num_missed)*1.0/num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Missed 23586 predictions out of 316650 samples for an accuracy of 0.926\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = res.predict(test_df)\n",
    "diff = (test_predictions - test_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(test_predictions)\n",
    "accuracy = (num_labels - num_missed) * 1.0/num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Missed 4765 predictions out of 35184 samples for an accuracy of 0.865\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_mat = confusion_matrix(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3576, 0, 0, 0, 2, 0, 0, 0, 188, 11]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_mat[0, :].tolist() + [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathutils.get_data_file(\"prob-synthea-1/output/labels_short_map.json\")) as fp:\n",
    "    label_map = json.load(fp)\n",
    "\n",
    "cnf_mat, cnf_mat_str = report.pretty_print_confusion_matrix(test_labels, test_predictions, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        U    Ast    AS    Ph    Py    AB    ST    CS    Cy\n",
      "---  ----  -----  ----  ----  ----  ----  ----  ----  ----\n",
      "U    3576      0     0     0     2     0     0     0   188\n",
      "Ast     0   3623     2     2     0   313     0    14     0\n",
      "AS      0     16  2395     8     0    62    79  1386     0\n",
      "Ph      0     20    14  3857     0    24    51    11     0\n",
      "Py      2      1     0     1  3746     0     0     0    76\n",
      "AB      0    517    45    15     0  3253    48    89     0\n",
      "ST      0      7    16    18     0     6  3844    75     0\n",
      "CS      0     46  1207     9     0    80   157  2467     0\n",
      "Cy    104      0     0     0    54     0     0     0  3658\n"
     ]
    }
   ],
   "source": [
    "print(cnf_mat_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Symptoms to txt. \n",
    "###### To run this change the jupyter cell type to \"code\" from \"markdown\"\n",
    "\n",
    "```python\n",
    "symptoms_file = pathutils.get_data_file(\"prob-synthea-1/data/symptoms_db.json\")\n",
    "with open(symptoms_file) as fp:\n",
    "    d = json.load(fp)\n",
    "values = list(d.values())\n",
    "values.sort()\n",
    "\n",
    "symptoms_txt = pathutils.get_data_file(\"prob-synthea-1/data/symptoms_list.txt\")\n",
    "with open(symptoms_txt, \"w\") as fp:\n",
    "    fp.write(\"SLUG, DESCRIPTION\\n\")\n",
    "    for val in values:\n",
    "        parts = \" \".join(val.split(\"-\"))\n",
    "        fp.write(\"%s, %s\\n\" % (val, parts))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(1, os.cpu_count()//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
