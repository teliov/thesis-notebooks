{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can use the *thesislib* package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a random forest classifier on the train data\n",
    "# read in the filtered dataset and prep for training\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesislib.utils import pathutils\n",
    "from thesislib.utils.imput import utils as tutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(pathutils.get_data_directory(), \"plain-synthea/output\")\n",
    "DATA_DIR = os.path.join(pathutils.get_data_directory(), \"plain-synthea/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = os.path.join(OUTPUT_DIR, \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tutils.prep_data(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do something very basic to handle the class imbalance\n",
    "# select the class that is the min value. Use that as a threshold for the other classes\n",
    "# so if min class as 10 samples then we take 10 samples from everyother class and use this to\n",
    "# train!\n",
    "\n",
    "# classes were labelled in decreasing count, so class with label 9 has the least number of samples\n",
    "num_min = int(0.95 * train_df.loc[train_df['condition_labels'] == 9].count().mean())\n",
    "\n",
    "dfs = []\n",
    "val_dfs = []\n",
    "for idx in range(10):\n",
    "    tmp = train_df.loc[train_df['condition_labels'] == idx]\n",
    "    dfs.append(tmp[: num_min])\n",
    "    val_dfs.append(tmp[num_min: ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat(dfs)\n",
    "val_data = pd.concat(val_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector = train_data.drop(columns=['condition_labels'])\n",
    "train_labels = train_data['condition_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vector = val_data.drop(columns=['condition_labels'])\n",
    "val_labels = val_data['condition_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=140, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=2, random_state=None, verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.fit(train_vector, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_db_file = pathutils.get_data_file(\"plain-synthea/data/observations.json\")\n",
    "with open(observations_db_file) as f:\n",
    "    observations_db = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "\n",
      "patient_age, 52.6335\n",
      "Oral temperature, 26.8771\n",
      "marital_status_code, 6.0959\n",
      "race_code, 3.5315\n",
      "gender_code, 2.9724\n",
      "Body Weight, 1.0379\n",
      "Body Height, 0.9504\n",
      "Body Mass Index, 0.9365\n",
      "Systolic Blood Pressure, 0.8868\n",
      "Diastolic Blood Pressure, 0.7990\n",
      "Pain severity - 0-10 verbal numeric rating [Score] - Reported, 0.5893\n",
      "Tobacco smoking status NHIS, 0.3077\n",
      "Sodium, 0.2054\n",
      "Carbon Dioxide, 0.1611\n",
      "Hemoglobin A1c/Hemoglobin.total in Blood, 0.1553\n",
      "Urea Nitrogen, 0.1473\n",
      "Chloride, 0.1472\n",
      "Glucose, 0.1421\n",
      "Creatinine, 0.1360\n",
      "Total Cholesterol, 0.1322\n",
      "Calcium, 0.1307\n",
      "Low Density Lipoprotein Cholesterol, 0.1289\n",
      "Triglycerides, 0.1251\n",
      "High Density Lipoprotein Cholesterol, 0.1193\n",
      "Potassium, 0.1158\n",
      "Hematocrit [Volume Fraction] of Blood by Automated count, 0.0590\n",
      "Platelet mean volume [Entitic volume] in Blood by Automated count, 0.0474\n",
      "Hemoglobin [Mass/volume] in Blood, 0.0440\n",
      "MCH [Entitic mass] by Automated count, 0.0411\n",
      "Platelets [#/volume] in Blood by Automated count, 0.0410\n",
      "MCV [Entitic volume] by Automated count, 0.0399\n",
      "RBC Auto (Bld) [#/Vol], 0.0396\n",
      "WBC Auto (Bld) [#/Vol], 0.0394\n",
      "Microalbumin Creatinine Ratio, 0.0375\n",
      "Platelet distribution width [Entitic volume] in Blood by Automated count, 0.0364\n",
      "Estimated Glomerular Filtration Rate, 0.0310\n",
      "RDW - Erythrocyte distribution width Auto (RBC) [Entitic vol], 0.0301\n",
      "FEV1/FVC, 0.0253\n",
      "MCHC [Mass/volume] by Automated count, 0.0239\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Importances:\\n\")\n",
    "# which feature is the most relevant for classification??\n",
    "sorted_features_index = np.argsort(res.feature_importances_)\n",
    "\n",
    "meta_features = ['marital_status_code', 'gender_code', 'race_code', 'patient_age']\n",
    "\n",
    "for idx in sorted_features_index[::-1]:\n",
    "    feat_name = train_vector.columns[idx]\n",
    "    importance = res.feature_importances_[idx]\n",
    "    if feat_name in meta_features:\n",
    "        name = feat_name\n",
    "    elif feat_name == '32465-7_code':\n",
    "        name = observations_db['32465-7']\n",
    "    elif feat_name == '72166-2_code':\n",
    "        name = observations_db['72166-2']\n",
    "    else:\n",
    "        name = observations_db[feat_name]\n",
    "    \n",
    "    print(\"%s, %.4f\" % (name, importance*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "- Now the age is more important for the classification than it was when we did nothing to handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Missed 775 predictions out of 2470 samples for an accuracy of 0.686\n"
     ]
    }
   ],
   "source": [
    "# how about classifications, even on the training set??\n",
    "train_predictions = res.predict(train_vector)\n",
    "# how many labels did it predict correctly??\n",
    "diff = (train_predictions - train_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(train_predictions)\n",
    "accuracy = (num_labels - num_missed)*1.0/num_labels\n",
    "\n",
    "print(\"Train set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- This is lower than what we got without touching the class imbalance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: Missed 15717 predictions out of 24527 samples for an accuracy of 0.359\n"
     ]
    }
   ],
   "source": [
    "# how about classifications, on the val data\n",
    "val_predictions = res.predict(val_vector)\n",
    "# how many labels did it predict correctly??\n",
    "diff = (val_predictions - val_labels) != 0\n",
    "num_missed = np.sum(diff)\n",
    "num_labels = len(val_predictions)\n",
    "accuracy = (num_labels - num_missed)*1.0/num_labels\n",
    "\n",
    "print(\"Validation set: Missed %d predictions out of %d samples for an accuracy of %.3f\" % (num_missed, num_labels, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- Really terrible performance!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,   0,  21,  18,  11,   0,  18,  17,  32,   7],\n",
       "       [  0, 241,   0,   0,   0,   4,   0,   1,   0,   1],\n",
       "       [ 14,   0, 127,  16,   9,   0,  15,  18,  42,   6],\n",
       "       [  4,   0,  12, 144,   7,   0,  12,  18,  34,  16],\n",
       "       [  7,   0,  11,   3, 145,   0,   3,  14,   7,  57],\n",
       "       [  0,   4,   0,   1,   1, 241,   0,   0,   0,   0],\n",
       "       [ 10,   0,  22,  17,   9,   0, 122,  29,  34,   4],\n",
       "       [ 10,   0,  13,  10,   6,   0,  19, 141,  41,   7],\n",
       "       [  2,   0,  14,   8,   0,   0,  10,   8, 205,   0],\n",
       "       [  0,   0,   0,   2,  39,   0,   0,   0,   0, 206]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrices - train\n",
    "labels_index = train_labels.unique()\n",
    "confusion_matrix(train_labels, train_predictions, labels=labels_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- In general the confusion matrix on the train set is much better than when nothing was done to handle the class imbalance. There are fewer missclassifications of similar sinusitis conditions to the Viral sinuistis (label 0) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1689,    0, 1589,  964,  542,    0, 1318, 1714, 1789,  241],\n",
       "       [   3, 4262,    3,   14,   15, 1056,    2,    8,    4,    5],\n",
       "       [ 765,    1,  717,  410,  278,    1,  642,  758,  755,  134],\n",
       "       [ 178,    0,  161,  571,   57,    0,  168,  205,  249,  199],\n",
       "       [  39,    0,   61,   47,  559,    0,   47,   90,   47,  323],\n",
       "       [   1,  273,    0,    1,    9,  877,    0,    0,    0,    0],\n",
       "       [  60,    0,   53,   33,   17,    0,   41,   63,   47,    7],\n",
       "       [  48,    0,   56,   34,   15,    0,   40,   61,   52,    7],\n",
       "       [   4,    0,    5,    1,    0,    0,    2,    7,   20,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   13]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrices - val\n",
    "labels_index = val_labels.unique()\n",
    "confusion_matrix(val_labels, val_predictions, labels=labels_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- This is clearly a case of \"overfitting\" (which is even flattery considering that accuracy on the train set was just 64%\n",
    "\n",
    "Not even going to bother checking the test set (haha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "- The results do make sense in a way. In this case, 247 entries are simply not enough to discover the underlying xtics of the data and this explains why it completly fails on the validation set.\n",
    "- Also from the results of the confusion matrix in the train set it is clear that handling the class imbalance is very important and might be the key to pushing prediction somewhat higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
